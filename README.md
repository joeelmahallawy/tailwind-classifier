# Headwind

## Preface:

Nowadays, there are many ways to represent data and documents. A loss run report coming from Geico may look very different from the loss run reports generated by Aviva. Although they are in different formats, they still contain the same kind of underlying information that all loss run reports must have:

- Date of claim
- Date claim was reported
- Incident description (reason for claim)
- Type of claim (insurance policy)
- Amount paid to date by insurer in legal/defense costs
- Loss report valuation date

These (along with other points of data) fields are constant across all loss run reports and should not be left out.

## Problem:

Now that we’ve identified that a loss report can have many different formats, it’s challenging to be able to identify these documents on the fly, and even when we can, we now have some foreign PDF format. Why does this matter? Insurance companies spend hundreds of dummy hours reading through these reports and extracting data – it’s a very manual and tedious process that should not exist today.

## Solution:

We’ve talked about two problems so far: classifying and extracting. In this document, we will discuss how we leverage AI to solve the first problem: classification. With the current method, we can actually solve both problems (more on that below). The problem with PDFs is that they can contain tables, equations, and other representations that could be harder to parse. We tend to turn to AI for this because it functions quite well when dealing with unstructured data.

### Method 1 (ChatGPT):

Using OpenAI’s Assistant API, I added all the sample documents to its knowledge base (for file search), then parsed incoming PDFs as raw text (with `pdf-parse`) and asked the assistant to classify the document based on the examples it was given in its knowledge base.

**Pros:**

- AI will reject documents that don’t match any of the examples.
- Binary classifications (is or is not).

**Cons:**

- GPT can sometimes hallucinate or classify a document incorrectly (therefore we need to increase the temperature of the model so that it isn’t always wrong, but not always right).
- Can run out of input prompt tokens when classifying large documents.

### Method 2 (Sensible.so):

No need to reinvent the wheel – I found a document processing tool that already uses AI to classify and extract data from documents. Using Sensible, I can provide examples of documents so that I can later categorize documents by performing a similarity search to the example documents. On the low-level, Sensible performs vector search on the examples that it was given. This means that it will not directly classify a document, but rather it will provide a score for the similarity match of each document, and we just take the highest score document as the classification.

**Pros:**

- Can send raw file format to API endpoint (encoded bytes).
- Higher accuracy when classifying.

**Cons:**

- Will always classify a document even if it’s invalid (since it’s by similarity, it doesn’t reject a document and matches with the highest similarity score).

## Conclusion

All in all, parsing PDFs of different formats is an annoying problem, but we fortunately have AI. Using vector embeddings and vector search (Method 2), we can get more accurate results but can’t differentiate invalid files. With raw text parsing and passing it to ChatGPT (GPT-4), it’s trivial to get deterministic responses but will not be as accurate as using a tool like Sensible. This challenge was definitely fun and gave me a chance to play around with OpenAI’s assistants (which I had not had much time to play with so I’m happy), and it taught me a lot about the common problems that insurance companies face.

## Tech Stack

- Next.js
- TypeScript
- GPT-4
- Sensible
- Mantine UI (for good looking components)
